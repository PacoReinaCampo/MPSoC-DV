behavioral
├── activity
│   ├── controller
│   │   ├── FNN
│   │   │   ├── convolutional
│   │   │   │   └── ntm_controller.dot
│   │   │   └── standard
│   │   │       └── ntm_controller.dot
│   │   ├── LSTM
│   │   │   ├── convolutional
│   │   │   │   ├── ntm_activation_gate_vector.dot
│   │   │   │   ├── ntm_controller.dot
│   │   │   │   ├── ntm_forget_gate_vector.dot
│   │   │   │   ├── ntm_hidden_gate_vector.dot
│   │   │   │   ├── ntm_input_gate_vector.dot
│   │   │   │   ├── ntm_output_gate_vector.dot
│   │   │   │   └── ntm_state_gate_vector.dot
│   │   │   └── standard
│   │   │       ├── ntm_activation_gate_vector.dot
│   │   │       ├── ntm_controller.dot
│   │   │       ├── ntm_forget_gate_vector.dot
│   │   │       ├── ntm_hidden_gate_vector.dot
│   │   │       ├── ntm_input_gate_vector.dot
│   │   │       ├── ntm_output_gate_vector.dot
│   │   │       └── ntm_state_gate_vector.dot
│   │   └── transformer
│   │       ├── components
│   │       │   ├── ntm_masked_multi_head_attention.dot
│   │       │   ├── ntm_masked_scaled_dot_product_attention.dot
│   │       │   ├── ntm_multi_head_attention.dot
│   │       │   └── ntm_scaled_dot_product_attention.dot
│   │       ├── fnn
│   │       │   └── ntm_fnn.dot
│   │       ├── functions
│   │       │   ├── ntm_layer_norm.dot
│   │       │   └── ntm_positional_encoding.dot
│   │       ├── inputs
│   │       │   ├── ntm_inputs_vector.dot
│   │       │   ├── ntm_keys_vector.dot
│   │       │   ├── ntm_queries_vector.dot
│   │       │   └── ntm_values_vector.dot
│   │       ├── lstm
│   │       │   ├── ntm_activation_gate_vector.dot
│   │       │   ├── ntm_forget_gate_vector.dot
│   │       │   ├── ntm_hidden_gate_vector.dot
│   │       │   ├── ntm_input_gate_vector.dot
│   │       │   ├── ntm_lstm.dot
│   │       │   ├── ntm_output_gate_vector.dot
│   │       │   └── ntm_state_gate_vector.dot
│   │       └── top
│   │           ├── ntm_controller.dot
│   │           ├── ntm_decoder.dot
│   │           └── ntm_encoder.dot
│   ├── dnc
│   │   ├── memory
│   │   │   ├── dnc_addressing.dot
│   │   │   ├── dnc_allocation_weighting.dot
│   │   │   ├── dnc_backward_weighting.dot
│   │   │   ├── dnc_forward_weighting.dot
│   │   │   ├── dnc_matrix_content_based_addressing.dot
│   │   │   ├── dnc_memory_matrix.dot
│   │   │   ├── dnc_memory_retention_vector.dot
│   │   │   ├── dnc_precedence_weighting.dot
│   │   │   ├── dnc_read_content_weighting.dot
│   │   │   ├── dnc_read_vectors.dot
│   │   │   ├── dnc_read_weighting.dot
│   │   │   ├── dnc_sort_vector.dot
│   │   │   ├── dnc_temporal_link_matrix.dot
│   │   │   ├── dnc_usage_vector.dot
│   │   │   ├── dnc_vector_content_based_addressing.dot
│   │   │   ├── dnc_write_content_weighting.dot
│   │   │   └── dnc_write_weighting.dot
│   │   ├── top
│   │   │   ├── dnc_interface_matrix.dot
│   │   │   ├── dnc_interface_top.dot
│   │   │   ├── dnc_interface_vector.dot
│   │   │   ├── dnc_output_vector.dot
│   │   │   └── dnc_top.dot
│   │   └── trained
│   │       └── dnc_trained_top.dot
│   ├── ntm
│   │   ├── memory
│   │   │   ├── ntm_addressing.dot
│   │   │   ├── ntm_matrix_content_based_addressing.dot
│   │   │   └── ntm_vector_content_based_addressing.dot
│   │   ├── read_heads
│   │   │   └── ntm_reading.dot
│   │   ├── top
│   │   │   ├── ntm_interface_matrix.dot
│   │   │   ├── ntm_interface_top.dot
│   │   │   ├── ntm_interface_vector.dot
│   │   │   ├── ntm_output_vector.dot
│   │   │   └── ntm_top.dot
│   │   ├── trained
│   │   │   └── ntm_trained_top.dot
│   │   └── write_heads
│   │       ├── ntm_erasing.dot
│   │       └── ntm_writing.dot
│   ├── state
│   │   ├── feedback
│   │   │   ├── ntm_state_matrix_feedforward.dot
│   │   │   ├── ntm_state_matrix_input.dot
│   │   │   ├── ntm_state_matrix_output.dot
│   │   │   └── ntm_state_matrix_state.dot
│   │   ├── outputs
│   │   │   ├── ntm_state_vector_output.dot
│   │   │   └── ntm_state_vector_state.dot
│   │   └── top
│   │       └── ntm_state_top.dot
│   └── trainer
│       ├── differentiation
│       │   ├── ntm_matrix_controller_differentiation.dot
│       │   └── ntm_vector_controller_differentiation.dot
│       ├── FNN
│       │   ├── ntm_fnn_b_trainer.dot
│       │   ├── ntm_fnn_d_trainer.dot
│       │   ├── ntm_fnn_k_trainer.dot
│       │   ├── ntm_fnn_trainer.dot
│       │   ├── ntm_fnn_u_trainer.dot
│       │   ├── ntm_fnn_v_trainer.dot
│       │   └── ntm_fnn_w_trainer.dot
│       └── LSTM
│           ├── activation
│           │   ├── ntm_lstm_activation_b_trainer.dot
│           │   ├── ntm_lstm_activation_d_trainer.dot
│           │   ├── ntm_lstm_activation_k_trainer.dot
│           │   ├── ntm_lstm_activation_trainer.dot
│           │   ├── ntm_lstm_activation_u_trainer.dot
│           │   ├── ntm_lstm_activation_v_trainer.dot
│           │   └── ntm_lstm_activation_w_trainer.dot
│           ├── forget
│           │   ├── ntm_lstm_forget_b_trainer.dot
│           │   ├── ntm_lstm_forget_d_trainer.dot
│           │   ├── ntm_lstm_forget_k_trainer.dot
│           │   ├── ntm_lstm_forget_trainer.dot
│           │   ├── ntm_lstm_forget_u_trainer.dot
│           │   ├── ntm_lstm_forget_v_trainer.dot
│           │   └── ntm_lstm_forget_w_trainer.dot
│           ├── input
│           │   ├── ntm_lstm_input_b_trainer.dot
│           │   ├── ntm_lstm_input_d_trainer.dot
│           │   ├── ntm_lstm_input_k_trainer.dot
│           │   ├── ntm_lstm_input_trainer.dot
│           │   ├── ntm_lstm_input_u_trainer.dot
│           │   ├── ntm_lstm_input_v_trainer.dot
│           │   └── ntm_lstm_input_w_trainer.dot
│           └── output
│               ├── ntm_lstm_output_b_trainer.dot
│               ├── ntm_lstm_output_d_trainer.dot
│               ├── ntm_lstm_output_k_trainer.dot
│               ├── ntm_lstm_output_trainer.dot
│               ├── ntm_lstm_output_u_trainer.dot
│               ├── ntm_lstm_output_v_trainer.dot
│               └── ntm_lstm_output_w_trainer.dot
├── communication
│   ├── controller
│   │   ├── FNN
│   │   │   ├── convolutional
│   │   │   │   └── ntm_controller.dot
│   │   │   └── standard
│   │   │       └── ntm_controller.dot
│   │   ├── LSTM
│   │   │   ├── convolutional
│   │   │   │   ├── ntm_activation_gate_vector.dot
│   │   │   │   ├── ntm_controller.dot
│   │   │   │   ├── ntm_forget_gate_vector.dot
│   │   │   │   ├── ntm_hidden_gate_vector.dot
│   │   │   │   ├── ntm_input_gate_vector.dot
│   │   │   │   ├── ntm_output_gate_vector.dot
│   │   │   │   └── ntm_state_gate_vector.dot
│   │   │   └── standard
│   │   │       ├── ntm_activation_gate_vector.dot
│   │   │       ├── ntm_controller.dot
│   │   │       ├── ntm_forget_gate_vector.dot
│   │   │       ├── ntm_hidden_gate_vector.dot
│   │   │       ├── ntm_input_gate_vector.dot
│   │   │       ├── ntm_output_gate_vector.dot
│   │   │       └── ntm_state_gate_vector.dot
│   │   └── transformer
│   │       ├── components
│   │       │   ├── ntm_masked_multi_head_attention.dot
│   │       │   ├── ntm_masked_scaled_dot_product_attention.dot
│   │       │   ├── ntm_multi_head_attention.dot
│   │       │   └── ntm_scaled_dot_product_attention.dot
│   │       ├── fnn
│   │       │   └── ntm_fnn.dot
│   │       ├── functions
│   │       │   ├── ntm_layer_norm.dot
│   │       │   └── ntm_positional_encoding.dot
│   │       ├── inputs
│   │       │   ├── ntm_inputs_vector.dot
│   │       │   ├── ntm_keys_vector.dot
│   │       │   ├── ntm_queries_vector.dot
│   │       │   └── ntm_values_vector.dot
│   │       ├── lstm
│   │       │   ├── ntm_activation_gate_vector.dot
│   │       │   ├── ntm_forget_gate_vector.dot
│   │       │   ├── ntm_hidden_gate_vector.dot
│   │       │   ├── ntm_input_gate_vector.dot
│   │       │   ├── ntm_lstm.dot
│   │       │   ├── ntm_output_gate_vector.dot
│   │       │   └── ntm_state_gate_vector.dot
│   │       └── top
│   │           ├── ntm_controller.dot
│   │           ├── ntm_decoder.dot
│   │           └── ntm_encoder.dot
│   ├── dnc
│   │   ├── memory
│   │   │   ├── dnc_addressing.dot
│   │   │   ├── dnc_allocation_weighting.dot
│   │   │   ├── dnc_backward_weighting.dot
│   │   │   ├── dnc_forward_weighting.dot
│   │   │   ├── dnc_matrix_content_based_addressing.dot
│   │   │   ├── dnc_memory_matrix.dot
│   │   │   ├── dnc_memory_retention_vector.dot
│   │   │   ├── dnc_precedence_weighting.dot
│   │   │   ├── dnc_read_content_weighting.dot
│   │   │   ├── dnc_read_vectors.dot
│   │   │   ├── dnc_read_weighting.dot
│   │   │   ├── dnc_sort_vector.dot
│   │   │   ├── dnc_temporal_link_matrix.dot
│   │   │   ├── dnc_usage_vector.dot
│   │   │   ├── dnc_vector_content_based_addressing.dot
│   │   │   ├── dnc_write_content_weighting.dot
│   │   │   └── dnc_write_weighting.dot
│   │   ├── top
│   │   │   ├── dnc_interface_matrix.dot
│   │   │   ├── dnc_interface_top.dot
│   │   │   ├── dnc_interface_vector.dot
│   │   │   ├── dnc_output_vector.dot
│   │   │   └── dnc_top.dot
│   │   └── trained
│   │       └── dnc_trained_top.dot
│   ├── ntm
│   │   ├── memory
│   │   │   ├── ntm_addressing.dot
│   │   │   ├── ntm_matrix_content_based_addressing.dot
│   │   │   └── ntm_vector_content_based_addressing.dot
│   │   ├── read_heads
│   │   │   └── ntm_reading.dot
│   │   ├── top
│   │   │   ├── ntm_interface_matrix.dot
│   │   │   ├── ntm_interface_top.dot
│   │   │   ├── ntm_interface_vector.dot
│   │   │   ├── ntm_output_vector.dot
│   │   │   └── ntm_top.dot
│   │   ├── trained
│   │   │   └── ntm_trained_top.dot
│   │   └── write_heads
│   │       ├── ntm_erasing.dot
│   │       └── ntm_writing.dot
│   ├── state
│   │   ├── feedback
│   │   │   ├── ntm_state_matrix_feedforward.dot
│   │   │   ├── ntm_state_matrix_input.dot
│   │   │   ├── ntm_state_matrix_output.dot
│   │   │   └── ntm_state_matrix_state.dot
│   │   ├── outputs
│   │   │   ├── ntm_state_vector_output.dot
│   │   │   └── ntm_state_vector_state.dot
│   │   └── top
│   │       └── ntm_state_top.dot
│   └── trainer
│       ├── differentiation
│       │   ├── ntm_matrix_controller_differentiation.dot
│       │   └── ntm_vector_controller_differentiation.dot
│       ├── FNN
│       │   ├── ntm_fnn_b_trainer.dot
│       │   ├── ntm_fnn_d_trainer.dot
│       │   ├── ntm_fnn_k_trainer.dot
│       │   ├── ntm_fnn_trainer.dot
│       │   ├── ntm_fnn_u_trainer.dot
│       │   ├── ntm_fnn_v_trainer.dot
│       │   └── ntm_fnn_w_trainer.dot
│       └── LSTM
│           ├── activation
│           │   ├── ntm_lstm_activation_b_trainer.dot
│           │   ├── ntm_lstm_activation_d_trainer.dot
│           │   ├── ntm_lstm_activation_k_trainer.dot
│           │   ├── ntm_lstm_activation_trainer.dot
│           │   ├── ntm_lstm_activation_u_trainer.dot
│           │   ├── ntm_lstm_activation_v_trainer.dot
│           │   └── ntm_lstm_activation_w_trainer.dot
│           ├── forget
│           │   ├── ntm_lstm_forget_b_trainer.dot
│           │   ├── ntm_lstm_forget_d_trainer.dot
│           │   ├── ntm_lstm_forget_k_trainer.dot
│           │   ├── ntm_lstm_forget_trainer.dot
│           │   ├── ntm_lstm_forget_u_trainer.dot
│           │   ├── ntm_lstm_forget_v_trainer.dot
│           │   └── ntm_lstm_forget_w_trainer.dot
│           ├── input
│           │   ├── ntm_lstm_input_b_trainer.dot
│           │   ├── ntm_lstm_input_d_trainer.dot
│           │   ├── ntm_lstm_input_k_trainer.dot
│           │   ├── ntm_lstm_input_trainer.dot
│           │   ├── ntm_lstm_input_u_trainer.dot
│           │   ├── ntm_lstm_input_v_trainer.dot
│           │   └── ntm_lstm_input_w_trainer.dot
│           └── output
│               ├── ntm_lstm_output_b_trainer.dot
│               ├── ntm_lstm_output_d_trainer.dot
│               ├── ntm_lstm_output_k_trainer.dot
│               ├── ntm_lstm_output_trainer.dot
│               ├── ntm_lstm_output_u_trainer.dot
│               ├── ntm_lstm_output_v_trainer.dot
│               └── ntm_lstm_output_w_trainer.dot
├── interaction
│   ├── controller
│   │   ├── FNN
│   │   │   ├── convolutional
│   │   │   │   └── ntm_controller.dot
│   │   │   └── standard
│   │   │       └── ntm_controller.dot
│   │   ├── LSTM
│   │   │   ├── convolutional
│   │   │   │   ├── ntm_activation_gate_vector.dot
│   │   │   │   ├── ntm_controller.dot
│   │   │   │   ├── ntm_forget_gate_vector.dot
│   │   │   │   ├── ntm_hidden_gate_vector.dot
│   │   │   │   ├── ntm_input_gate_vector.dot
│   │   │   │   ├── ntm_output_gate_vector.dot
│   │   │   │   └── ntm_state_gate_vector.dot
│   │   │   └── standard
│   │   │       ├── ntm_activation_gate_vector.dot
│   │   │       ├── ntm_controller.dot
│   │   │       ├── ntm_forget_gate_vector.dot
│   │   │       ├── ntm_hidden_gate_vector.dot
│   │   │       ├── ntm_input_gate_vector.dot
│   │   │       ├── ntm_output_gate_vector.dot
│   │   │       └── ntm_state_gate_vector.dot
│   │   └── transformer
│   │       ├── components
│   │       │   ├── ntm_masked_multi_head_attention.dot
│   │       │   ├── ntm_masked_scaled_dot_product_attention.dot
│   │       │   ├── ntm_multi_head_attention.dot
│   │       │   └── ntm_scaled_dot_product_attention.dot
│   │       ├── fnn
│   │       │   └── ntm_fnn.dot
│   │       ├── functions
│   │       │   ├── ntm_layer_norm.dot
│   │       │   └── ntm_positional_encoding.dot
│   │       ├── inputs
│   │       │   ├── ntm_inputs_vector.dot
│   │       │   ├── ntm_keys_vector.dot
│   │       │   ├── ntm_queries_vector.dot
│   │       │   └── ntm_values_vector.dot
│   │       ├── lstm
│   │       │   ├── ntm_activation_gate_vector.dot
│   │       │   ├── ntm_forget_gate_vector.dot
│   │       │   ├── ntm_hidden_gate_vector.dot
│   │       │   ├── ntm_input_gate_vector.dot
│   │       │   ├── ntm_lstm.dot
│   │       │   ├── ntm_output_gate_vector.dot
│   │       │   └── ntm_state_gate_vector.dot
│   │       └── top
│   │           ├── ntm_controller.dot
│   │           ├── ntm_decoder.dot
│   │           └── ntm_encoder.dot
│   ├── dnc
│   │   ├── memory
│   │   │   ├── dnc_addressing.dot
│   │   │   ├── dnc_allocation_weighting.dot
│   │   │   ├── dnc_backward_weighting.dot
│   │   │   ├── dnc_forward_weighting.dot
│   │   │   ├── dnc_matrix_content_based_addressing.dot
│   │   │   ├── dnc_memory_matrix.dot
│   │   │   ├── dnc_memory_retention_vector.dot
│   │   │   ├── dnc_precedence_weighting.dot
│   │   │   ├── dnc_read_content_weighting.dot
│   │   │   ├── dnc_read_vectors.dot
│   │   │   ├── dnc_read_weighting.dot
│   │   │   ├── dnc_sort_vector.dot
│   │   │   ├── dnc_temporal_link_matrix.dot
│   │   │   ├── dnc_usage_vector.dot
│   │   │   ├── dnc_vector_content_based_addressing.dot
│   │   │   ├── dnc_write_content_weighting.dot
│   │   │   └── dnc_write_weighting.dot
│   │   ├── top
│   │   │   ├── dnc_interface_matrix.dot
│   │   │   ├── dnc_interface_top.dot
│   │   │   ├── dnc_interface_vector.dot
│   │   │   ├── dnc_output_vector.dot
│   │   │   └── dnc_top.dot
│   │   └── trained
│   │       └── dnc_trained_top.dot
│   ├── ntm
│   │   ├── memory
│   │   │   ├── ntm_addressing.dot
│   │   │   ├── ntm_matrix_content_based_addressing.dot
│   │   │   └── ntm_vector_content_based_addressing.dot
│   │   ├── read_heads
│   │   │   └── ntm_reading.dot
│   │   ├── top
│   │   │   ├── ntm_interface_matrix.dot
│   │   │   ├── ntm_interface_top.dot
│   │   │   ├── ntm_interface_vector.dot
│   │   │   ├── ntm_output_vector.dot
│   │   │   └── ntm_top.dot
│   │   ├── trained
│   │   │   └── ntm_trained_top.dot
│   │   └── write_heads
│   │       ├── ntm_erasing.dot
│   │       └── ntm_writing.dot
│   ├── state
│   │   ├── feedback
│   │   │   ├── ntm_state_matrix_feedforward.dot
│   │   │   ├── ntm_state_matrix_input.dot
│   │   │   ├── ntm_state_matrix_output.dot
│   │   │   └── ntm_state_matrix_state.dot
│   │   ├── outputs
│   │   │   ├── ntm_state_vector_output.dot
│   │   │   └── ntm_state_vector_state.dot
│   │   └── top
│   │       └── ntm_state_top.dot
│   └── trainer
│       ├── differentiation
│       │   ├── ntm_matrix_controller_differentiation.dot
│       │   └── ntm_vector_controller_differentiation.dot
│       ├── FNN
│       │   ├── ntm_fnn_b_trainer.dot
│       │   ├── ntm_fnn_d_trainer.dot
│       │   ├── ntm_fnn_k_trainer.dot
│       │   ├── ntm_fnn_trainer.dot
│       │   ├── ntm_fnn_u_trainer.dot
│       │   ├── ntm_fnn_v_trainer.dot
│       │   └── ntm_fnn_w_trainer.dot
│       └── LSTM
│           ├── activation
│           │   ├── ntm_lstm_activation_b_trainer.dot
│           │   ├── ntm_lstm_activation_d_trainer.dot
│           │   ├── ntm_lstm_activation_k_trainer.dot
│           │   ├── ntm_lstm_activation_trainer.dot
│           │   ├── ntm_lstm_activation_u_trainer.dot
│           │   ├── ntm_lstm_activation_v_trainer.dot
│           │   └── ntm_lstm_activation_w_trainer.dot
│           ├── forget
│           │   ├── ntm_lstm_forget_b_trainer.dot
│           │   ├── ntm_lstm_forget_d_trainer.dot
│           │   ├── ntm_lstm_forget_k_trainer.dot
│           │   ├── ntm_lstm_forget_trainer.dot
│           │   ├── ntm_lstm_forget_u_trainer.dot
│           │   ├── ntm_lstm_forget_v_trainer.dot
│           │   └── ntm_lstm_forget_w_trainer.dot
│           ├── input
│           │   ├── ntm_lstm_input_b_trainer.dot
│           │   ├── ntm_lstm_input_d_trainer.dot
│           │   ├── ntm_lstm_input_k_trainer.dot
│           │   ├── ntm_lstm_input_trainer.dot
│           │   ├── ntm_lstm_input_u_trainer.dot
│           │   ├── ntm_lstm_input_v_trainer.dot
│           │   └── ntm_lstm_input_w_trainer.dot
│           └── output
│               ├── ntm_lstm_output_b_trainer.dot
│               ├── ntm_lstm_output_d_trainer.dot
│               ├── ntm_lstm_output_k_trainer.dot
│               ├── ntm_lstm_output_trainer.dot
│               ├── ntm_lstm_output_u_trainer.dot
│               ├── ntm_lstm_output_v_trainer.dot
│               └── ntm_lstm_output_w_trainer.dot
├── sequence
│   ├── controller
│   │   ├── FNN
│   │   │   ├── convolutional
│   │   │   │   └── ntm_controller.dot
│   │   │   └── standard
│   │   │       └── ntm_controller.dot
│   │   ├── LSTM
│   │   │   ├── convolutional
│   │   │   │   ├── ntm_activation_gate_vector.dot
│   │   │   │   ├── ntm_controller.dot
│   │   │   │   ├── ntm_forget_gate_vector.dot
│   │   │   │   ├── ntm_hidden_gate_vector.dot
│   │   │   │   ├── ntm_input_gate_vector.dot
│   │   │   │   ├── ntm_output_gate_vector.dot
│   │   │   │   └── ntm_state_gate_vector.dot
│   │   │   └── standard
│   │   │       ├── ntm_activation_gate_vector.dot
│   │   │       ├── ntm_controller.dot
│   │   │       ├── ntm_forget_gate_vector.dot
│   │   │       ├── ntm_hidden_gate_vector.dot
│   │   │       ├── ntm_input_gate_vector.dot
│   │   │       ├── ntm_output_gate_vector.dot
│   │   │       └── ntm_state_gate_vector.dot
│   │   └── transformer
│   │       ├── components
│   │       │   ├── ntm_masked_multi_head_attention.dot
│   │       │   ├── ntm_masked_scaled_dot_product_attention.dot
│   │       │   ├── ntm_multi_head_attention.dot
│   │       │   └── ntm_scaled_dot_product_attention.dot
│   │       ├── fnn
│   │       │   └── ntm_fnn.dot
│   │       ├── functions
│   │       │   ├── ntm_layer_norm.dot
│   │       │   └── ntm_positional_encoding.dot
│   │       ├── inputs
│   │       │   ├── ntm_inputs_vector.dot
│   │       │   ├── ntm_keys_vector.dot
│   │       │   ├── ntm_queries_vector.dot
│   │       │   └── ntm_values_vector.dot
│   │       ├── lstm
│   │       │   ├── ntm_activation_gate_vector.dot
│   │       │   ├── ntm_forget_gate_vector.dot
│   │       │   ├── ntm_hidden_gate_vector.dot
│   │       │   ├── ntm_input_gate_vector.dot
│   │       │   ├── ntm_lstm.dot
│   │       │   ├── ntm_output_gate_vector.dot
│   │       │   └── ntm_state_gate_vector.dot
│   │       └── top
│   │           ├── ntm_controller.dot
│   │           ├── ntm_decoder.dot
│   │           └── ntm_encoder.dot
│   ├── dnc
│   │   ├── memory
│   │   │   ├── dnc_addressing.dot
│   │   │   ├── dnc_allocation_weighting.dot
│   │   │   ├── dnc_backward_weighting.dot
│   │   │   ├── dnc_forward_weighting.dot
│   │   │   ├── dnc_matrix_content_based_addressing.dot
│   │   │   ├── dnc_memory_matrix.dot
│   │   │   ├── dnc_memory_retention_vector.dot
│   │   │   ├── dnc_precedence_weighting.dot
│   │   │   ├── dnc_read_content_weighting.dot
│   │   │   ├── dnc_read_vectors.dot
│   │   │   ├── dnc_read_weighting.dot
│   │   │   ├── dnc_sort_vector.dot
│   │   │   ├── dnc_temporal_link_matrix.dot
│   │   │   ├── dnc_usage_vector.dot
│   │   │   ├── dnc_vector_content_based_addressing.dot
│   │   │   ├── dnc_write_content_weighting.dot
│   │   │   └── dnc_write_weighting.dot
│   │   ├── top
│   │   │   ├── dnc_interface_matrix.dot
│   │   │   ├── dnc_interface_top.dot
│   │   │   ├── dnc_interface_vector.dot
│   │   │   ├── dnc_output_vector.dot
│   │   │   └── dnc_top.dot
│   │   └── trained
│   │       └── dnc_trained_top.dot
│   ├── ntm
│   │   ├── memory
│   │   │   ├── ntm_addressing.dot
│   │   │   ├── ntm_matrix_content_based_addressing.dot
│   │   │   └── ntm_vector_content_based_addressing.dot
│   │   ├── read_heads
│   │   │   └── ntm_reading.dot
│   │   ├── top
│   │   │   ├── ntm_interface_matrix.dot
│   │   │   ├── ntm_interface_top.dot
│   │   │   ├── ntm_interface_vector.dot
│   │   │   ├── ntm_output_vector.dot
│   │   │   └── ntm_top.dot
│   │   ├── trained
│   │   │   └── ntm_trained_top.dot
│   │   └── write_heads
│   │       ├── ntm_erasing.dot
│   │       └── ntm_writing.dot
│   ├── state
│   │   ├── feedback
│   │   │   ├── ntm_state_matrix_feedforward.dot
│   │   │   ├── ntm_state_matrix_input.dot
│   │   │   ├── ntm_state_matrix_output.dot
│   │   │   └── ntm_state_matrix_state.dot
│   │   ├── outputs
│   │   │   ├── ntm_state_vector_output.dot
│   │   │   └── ntm_state_vector_state.dot
│   │   └── top
│   │       └── ntm_state_top.dot
│   └── trainer
│       ├── differentiation
│       │   ├── ntm_matrix_controller_differentiation.dot
│       │   └── ntm_vector_controller_differentiation.dot
│       ├── FNN
│       │   ├── ntm_fnn_b_trainer.dot
│       │   ├── ntm_fnn_d_trainer.dot
│       │   ├── ntm_fnn_k_trainer.dot
│       │   ├── ntm_fnn_trainer.dot
│       │   ├── ntm_fnn_u_trainer.dot
│       │   ├── ntm_fnn_v_trainer.dot
│       │   └── ntm_fnn_w_trainer.dot
│       └── LSTM
│           ├── activation
│           │   ├── ntm_lstm_activation_b_trainer.dot
│           │   ├── ntm_lstm_activation_d_trainer.dot
│           │   ├── ntm_lstm_activation_k_trainer.dot
│           │   ├── ntm_lstm_activation_trainer.dot
│           │   ├── ntm_lstm_activation_u_trainer.dot
│           │   ├── ntm_lstm_activation_v_trainer.dot
│           │   └── ntm_lstm_activation_w_trainer.dot
│           ├── forget
│           │   ├── ntm_lstm_forget_b_trainer.dot
│           │   ├── ntm_lstm_forget_d_trainer.dot
│           │   ├── ntm_lstm_forget_k_trainer.dot
│           │   ├── ntm_lstm_forget_trainer.dot
│           │   ├── ntm_lstm_forget_u_trainer.dot
│           │   ├── ntm_lstm_forget_v_trainer.dot
│           │   └── ntm_lstm_forget_w_trainer.dot
│           ├── input
│           │   ├── ntm_lstm_input_b_trainer.dot
│           │   ├── ntm_lstm_input_d_trainer.dot
│           │   ├── ntm_lstm_input_k_trainer.dot
│           │   ├── ntm_lstm_input_trainer.dot
│           │   ├── ntm_lstm_input_u_trainer.dot
│           │   ├── ntm_lstm_input_v_trainer.dot
│           │   └── ntm_lstm_input_w_trainer.dot
│           └── output
│               ├── ntm_lstm_output_b_trainer.dot
│               ├── ntm_lstm_output_d_trainer.dot
│               ├── ntm_lstm_output_k_trainer.dot
│               ├── ntm_lstm_output_trainer.dot
│               ├── ntm_lstm_output_u_trainer.dot
│               ├── ntm_lstm_output_v_trainer.dot
│               └── ntm_lstm_output_w_trainer.dot
├── state
│   ├── controller
│   │   ├── FNN
│   │   │   ├── convolutional
│   │   │   │   └── ntm_controller.dot
│   │   │   └── standard
│   │   │       └── ntm_controller.dot
│   │   ├── LSTM
│   │   │   ├── convolutional
│   │   │   │   ├── ntm_activation_gate_vector.dot
│   │   │   │   ├── ntm_controller.dot
│   │   │   │   ├── ntm_forget_gate_vector.dot
│   │   │   │   ├── ntm_hidden_gate_vector.dot
│   │   │   │   ├── ntm_input_gate_vector.dot
│   │   │   │   ├── ntm_output_gate_vector.dot
│   │   │   │   └── ntm_state_gate_vector.dot
│   │   │   └── standard
│   │   │       ├── ntm_activation_gate_vector.dot
│   │   │       ├── ntm_controller.dot
│   │   │       ├── ntm_forget_gate_vector.dot
│   │   │       ├── ntm_hidden_gate_vector.dot
│   │   │       ├── ntm_input_gate_vector.dot
│   │   │       ├── ntm_output_gate_vector.dot
│   │   │       └── ntm_state_gate_vector.dot
│   │   └── transformer
│   │       ├── components
│   │       │   ├── ntm_masked_multi_head_attention.dot
│   │       │   ├── ntm_masked_scaled_dot_product_attention.dot
│   │       │   ├── ntm_multi_head_attention.dot
│   │       │   └── ntm_scaled_dot_product_attention.dot
│   │       ├── fnn
│   │       │   └── ntm_fnn.dot
│   │       ├── functions
│   │       │   ├── ntm_layer_norm.dot
│   │       │   └── ntm_positional_encoding.dot
│   │       ├── inputs
│   │       │   ├── ntm_inputs_vector.dot
│   │       │   ├── ntm_keys_vector.dot
│   │       │   ├── ntm_queries_vector.dot
│   │       │   └── ntm_values_vector.dot
│   │       ├── lstm
│   │       │   ├── ntm_activation_gate_vector.dot
│   │       │   ├── ntm_forget_gate_vector.dot
│   │       │   ├── ntm_hidden_gate_vector.dot
│   │       │   ├── ntm_input_gate_vector.dot
│   │       │   ├── ntm_lstm.dot
│   │       │   ├── ntm_output_gate_vector.dot
│   │       │   └── ntm_state_gate_vector.dot
│   │       └── top
│   │           ├── ntm_controller.dot
│   │           ├── ntm_decoder.dot
│   │           └── ntm_encoder.dot
│   ├── dnc
│   │   ├── memory
│   │   │   ├── dnc_addressing.dot
│   │   │   ├── dnc_allocation_weighting.dot
│   │   │   ├── dnc_backward_weighting.dot
│   │   │   ├── dnc_forward_weighting.dot
│   │   │   ├── dnc_matrix_content_based_addressing.dot
│   │   │   ├── dnc_memory_matrix.dot
│   │   │   ├── dnc_memory_retention_vector.dot
│   │   │   ├── dnc_precedence_weighting.dot
│   │   │   ├── dnc_read_content_weighting.dot
│   │   │   ├── dnc_read_vectors.dot
│   │   │   ├── dnc_read_weighting.dot
│   │   │   ├── dnc_sort_vector.dot
│   │   │   ├── dnc_temporal_link_matrix.dot
│   │   │   ├── dnc_usage_vector.dot
│   │   │   ├── dnc_vector_content_based_addressing.dot
│   │   │   ├── dnc_write_content_weighting.dot
│   │   │   └── dnc_write_weighting.dot
│   │   ├── top
│   │   │   ├── dnc_interface_matrix.dot
│   │   │   ├── dnc_interface_top.dot
│   │   │   ├── dnc_interface_vector.dot
│   │   │   ├── dnc_output_vector.dot
│   │   │   └── dnc_top.dot
│   │   └── trained
│   │       └── dnc_trained_top.dot
│   ├── ntm
│   │   ├── memory
│   │   │   ├── ntm_addressing.dot
│   │   │   ├── ntm_matrix_content_based_addressing.dot
│   │   │   └── ntm_vector_content_based_addressing.dot
│   │   ├── read_heads
│   │   │   └── ntm_reading.dot
│   │   ├── top
│   │   │   ├── ntm_interface_matrix.dot
│   │   │   ├── ntm_interface_top.dot
│   │   │   ├── ntm_interface_vector.dot
│   │   │   ├── ntm_output_vector.dot
│   │   │   └── ntm_top.dot
│   │   ├── trained
│   │   │   └── ntm_trained_top.dot
│   │   └── write_heads
│   │       ├── ntm_erasing.dot
│   │       └── ntm_writing.dot
│   ├── state
│   │   ├── feedback
│   │   │   ├── ntm_state_matrix_feedforward.dot
│   │   │   ├── ntm_state_matrix_input.dot
│   │   │   ├── ntm_state_matrix_output.dot
│   │   │   └── ntm_state_matrix_state.dot
│   │   ├── outputs
│   │   │   ├── ntm_state_vector_output.dot
│   │   │   └── ntm_state_vector_state.dot
│   │   └── top
│   │       └── ntm_state_top.dot
│   └── trainer
│       ├── differentiation
│       │   ├── ntm_matrix_controller_differentiation.dot
│       │   └── ntm_vector_controller_differentiation.dot
│       ├── FNN
│       │   ├── ntm_fnn_b_trainer.dot
│       │   ├── ntm_fnn_d_trainer.dot
│       │   ├── ntm_fnn_k_trainer.dot
│       │   ├── ntm_fnn_trainer.dot
│       │   ├── ntm_fnn_u_trainer.dot
│       │   ├── ntm_fnn_v_trainer.dot
│       │   └── ntm_fnn_w_trainer.dot
│       └── LSTM
│           ├── activation
│           │   ├── ntm_lstm_activation_b_trainer.dot
│           │   ├── ntm_lstm_activation_d_trainer.dot
│           │   ├── ntm_lstm_activation_k_trainer.dot
│           │   ├── ntm_lstm_activation_trainer.dot
│           │   ├── ntm_lstm_activation_u_trainer.dot
│           │   ├── ntm_lstm_activation_v_trainer.dot
│           │   └── ntm_lstm_activation_w_trainer.dot
│           ├── forget
│           │   ├── ntm_lstm_forget_b_trainer.dot
│           │   ├── ntm_lstm_forget_d_trainer.dot
│           │   ├── ntm_lstm_forget_k_trainer.dot
│           │   ├── ntm_lstm_forget_trainer.dot
│           │   ├── ntm_lstm_forget_u_trainer.dot
│           │   ├── ntm_lstm_forget_v_trainer.dot
│           │   └── ntm_lstm_forget_w_trainer.dot
│           ├── input
│           │   ├── ntm_lstm_input_b_trainer.dot
│           │   ├── ntm_lstm_input_d_trainer.dot
│           │   ├── ntm_lstm_input_k_trainer.dot
│           │   ├── ntm_lstm_input_trainer.dot
│           │   ├── ntm_lstm_input_u_trainer.dot
│           │   ├── ntm_lstm_input_v_trainer.dot
│           │   └── ntm_lstm_input_w_trainer.dot
│           └── output
│               ├── ntm_lstm_output_b_trainer.dot
│               ├── ntm_lstm_output_d_trainer.dot
│               ├── ntm_lstm_output_k_trainer.dot
│               ├── ntm_lstm_output_trainer.dot
│               ├── ntm_lstm_output_u_trainer.dot
│               ├── ntm_lstm_output_v_trainer.dot
│               └── ntm_lstm_output_w_trainer.dot
├── timing
│   ├── controller
│   │   ├── FNN
│   │   │   ├── convolutional
│   │   │   │   └── ntm_controller.dot
│   │   │   └── standard
│   │   │       └── ntm_controller.dot
│   │   ├── LSTM
│   │   │   ├── convolutional
│   │   │   │   ├── ntm_activation_gate_vector.dot
│   │   │   │   ├── ntm_controller.dot
│   │   │   │   ├── ntm_forget_gate_vector.dot
│   │   │   │   ├── ntm_hidden_gate_vector.dot
│   │   │   │   ├── ntm_input_gate_vector.dot
│   │   │   │   ├── ntm_output_gate_vector.dot
│   │   │   │   └── ntm_state_gate_vector.dot
│   │   │   └── standard
│   │   │       ├── ntm_activation_gate_vector.dot
│   │   │       ├── ntm_controller.dot
│   │   │       ├── ntm_forget_gate_vector.dot
│   │   │       ├── ntm_hidden_gate_vector.dot
│   │   │       ├── ntm_input_gate_vector.dot
│   │   │       ├── ntm_output_gate_vector.dot
│   │   │       └── ntm_state_gate_vector.dot
│   │   └── transformer
│   │       ├── components
│   │       │   ├── ntm_masked_multi_head_attention.dot
│   │       │   ├── ntm_masked_scaled_dot_product_attention.dot
│   │       │   ├── ntm_multi_head_attention.dot
│   │       │   └── ntm_scaled_dot_product_attention.dot
│   │       ├── fnn
│   │       │   └── ntm_fnn.dot
│   │       ├── functions
│   │       │   ├── ntm_layer_norm.dot
│   │       │   └── ntm_positional_encoding.dot
│   │       ├── inputs
│   │       │   ├── ntm_inputs_vector.dot
│   │       │   ├── ntm_keys_vector.dot
│   │       │   ├── ntm_queries_vector.dot
│   │       │   └── ntm_values_vector.dot
│   │       ├── lstm
│   │       │   ├── ntm_activation_gate_vector.dot
│   │       │   ├── ntm_forget_gate_vector.dot
│   │       │   ├── ntm_hidden_gate_vector.dot
│   │       │   ├── ntm_input_gate_vector.dot
│   │       │   ├── ntm_lstm.dot
│   │       │   ├── ntm_output_gate_vector.dot
│   │       │   └── ntm_state_gate_vector.dot
│   │       └── top
│   │           ├── ntm_controller.dot
│   │           ├── ntm_decoder.dot
│   │           └── ntm_encoder.dot
│   ├── dnc
│   │   ├── memory
│   │   │   ├── dnc_addressing.dot
│   │   │   ├── dnc_allocation_weighting.dot
│   │   │   ├── dnc_backward_weighting.dot
│   │   │   ├── dnc_forward_weighting.dot
│   │   │   ├── dnc_matrix_content_based_addressing.dot
│   │   │   ├── dnc_memory_matrix.dot
│   │   │   ├── dnc_memory_retention_vector.dot
│   │   │   ├── dnc_precedence_weighting.dot
│   │   │   ├── dnc_read_content_weighting.dot
│   │   │   ├── dnc_read_vectors.dot
│   │   │   ├── dnc_read_weighting.dot
│   │   │   ├── dnc_sort_vector.dot
│   │   │   ├── dnc_temporal_link_matrix.dot
│   │   │   ├── dnc_usage_vector.dot
│   │   │   ├── dnc_vector_content_based_addressing.dot
│   │   │   ├── dnc_write_content_weighting.dot
│   │   │   └── dnc_write_weighting.dot
│   │   ├── top
│   │   │   ├── dnc_interface_matrix.dot
│   │   │   ├── dnc_interface_top.dot
│   │   │   ├── dnc_interface_vector.dot
│   │   │   ├── dnc_output_vector.dot
│   │   │   └── dnc_top.dot
│   │   └── trained
│   │       └── dnc_trained_top.dot
│   ├── ntm
│   │   ├── memory
│   │   │   ├── ntm_addressing.dot
│   │   │   ├── ntm_matrix_content_based_addressing.dot
│   │   │   └── ntm_vector_content_based_addressing.dot
│   │   ├── read_heads
│   │   │   └── ntm_reading.dot
│   │   ├── top
│   │   │   ├── ntm_interface_matrix.dot
│   │   │   ├── ntm_interface_top.dot
│   │   │   ├── ntm_interface_vector.dot
│   │   │   ├── ntm_output_vector.dot
│   │   │   └── ntm_top.dot
│   │   ├── trained
│   │   │   └── ntm_trained_top.dot
│   │   └── write_heads
│   │       ├── ntm_erasing.dot
│   │       └── ntm_writing.dot
│   ├── state
│   │   ├── feedback
│   │   │   ├── ntm_state_matrix_feedforward.dot
│   │   │   ├── ntm_state_matrix_input.dot
│   │   │   ├── ntm_state_matrix_output.dot
│   │   │   └── ntm_state_matrix_state.dot
│   │   ├── outputs
│   │   │   ├── ntm_state_vector_output.dot
│   │   │   └── ntm_state_vector_state.dot
│   │   └── top
│   │       └── ntm_state_top.dot
│   └── trainer
│       ├── differentiation
│       │   ├── ntm_matrix_controller_differentiation.dot
│       │   └── ntm_vector_controller_differentiation.dot
│       ├── FNN
│       │   ├── ntm_fnn_b_trainer.dot
│       │   ├── ntm_fnn_d_trainer.dot
│       │   ├── ntm_fnn_k_trainer.dot
│       │   ├── ntm_fnn_trainer.dot
│       │   ├── ntm_fnn_u_trainer.dot
│       │   ├── ntm_fnn_v_trainer.dot
│       │   └── ntm_fnn_w_trainer.dot
│       └── LSTM
│           ├── activation
│           │   ├── ntm_lstm_activation_b_trainer.dot
│           │   ├── ntm_lstm_activation_d_trainer.dot
│           │   ├── ntm_lstm_activation_k_trainer.dot
│           │   ├── ntm_lstm_activation_trainer.dot
│           │   ├── ntm_lstm_activation_u_trainer.dot
│           │   ├── ntm_lstm_activation_v_trainer.dot
│           │   └── ntm_lstm_activation_w_trainer.dot
│           ├── forget
│           │   ├── ntm_lstm_forget_b_trainer.dot
│           │   ├── ntm_lstm_forget_d_trainer.dot
│           │   ├── ntm_lstm_forget_k_trainer.dot
│           │   ├── ntm_lstm_forget_trainer.dot
│           │   ├── ntm_lstm_forget_u_trainer.dot
│           │   ├── ntm_lstm_forget_v_trainer.dot
│           │   └── ntm_lstm_forget_w_trainer.dot
│           ├── input
│           │   ├── ntm_lstm_input_b_trainer.dot
│           │   ├── ntm_lstm_input_d_trainer.dot
│           │   ├── ntm_lstm_input_k_trainer.dot
│           │   ├── ntm_lstm_input_trainer.dot
│           │   ├── ntm_lstm_input_u_trainer.dot
│           │   ├── ntm_lstm_input_v_trainer.dot
│           │   └── ntm_lstm_input_w_trainer.dot
│           └── output
│               ├── ntm_lstm_output_b_trainer.dot
│               ├── ntm_lstm_output_d_trainer.dot
│               ├── ntm_lstm_output_k_trainer.dot
│               ├── ntm_lstm_output_trainer.dot
│               ├── ntm_lstm_output_u_trainer.dot
│               ├── ntm_lstm_output_v_trainer.dot
│               └── ntm_lstm_output_w_trainer.dot
└── use
    ├── controller
    │   ├── FNN
    │   │   ├── convolutional
    │   │   │   └── ntm_controller.dot
    │   │   └── standard
    │   │       └── ntm_controller.dot
    │   ├── LSTM
    │   │   ├── convolutional
    │   │   │   ├── ntm_activation_gate_vector.dot
    │   │   │   ├── ntm_controller.dot
    │   │   │   ├── ntm_forget_gate_vector.dot
    │   │   │   ├── ntm_hidden_gate_vector.dot
    │   │   │   ├── ntm_input_gate_vector.dot
    │   │   │   ├── ntm_output_gate_vector.dot
    │   │   │   └── ntm_state_gate_vector.dot
    │   │   └── standard
    │   │       ├── ntm_activation_gate_vector.dot
    │   │       ├── ntm_controller.dot
    │   │       ├── ntm_forget_gate_vector.dot
    │   │       ├── ntm_hidden_gate_vector.dot
    │   │       ├── ntm_input_gate_vector.dot
    │   │       ├── ntm_output_gate_vector.dot
    │   │       └── ntm_state_gate_vector.dot
    │   └── transformer
    │       ├── components
    │       │   ├── ntm_masked_multi_head_attention.dot
    │       │   ├── ntm_masked_scaled_dot_product_attention.dot
    │       │   ├── ntm_multi_head_attention.dot
    │       │   └── ntm_scaled_dot_product_attention.dot
    │       ├── fnn
    │       │   └── ntm_fnn.dot
    │       ├── functions
    │       │   ├── ntm_layer_norm.dot
    │       │   └── ntm_positional_encoding.dot
    │       ├── inputs
    │       │   ├── ntm_inputs_vector.dot
    │       │   ├── ntm_keys_vector.dot
    │       │   ├── ntm_queries_vector.dot
    │       │   └── ntm_values_vector.dot
    │       ├── lstm
    │       │   ├── ntm_activation_gate_vector.dot
    │       │   ├── ntm_forget_gate_vector.dot
    │       │   ├── ntm_hidden_gate_vector.dot
    │       │   ├── ntm_input_gate_vector.dot
    │       │   ├── ntm_lstm.dot
    │       │   ├── ntm_output_gate_vector.dot
    │       │   └── ntm_state_gate_vector.dot
    │       └── top
    │           ├── ntm_controller.dot
    │           ├── ntm_decoder.dot
    │           └── ntm_encoder.dot
    ├── dnc
    │   ├── memory
    │   │   ├── dnc_addressing.dot
    │   │   ├── dnc_allocation_weighting.dot
    │   │   ├── dnc_backward_weighting.dot
    │   │   ├── dnc_forward_weighting.dot
    │   │   ├── dnc_matrix_content_based_addressing.dot
    │   │   ├── dnc_memory_matrix.dot
    │   │   ├── dnc_memory_retention_vector.dot
    │   │   ├── dnc_precedence_weighting.dot
    │   │   ├── dnc_read_content_weighting.dot
    │   │   ├── dnc_read_vectors.dot
    │   │   ├── dnc_read_weighting.dot
    │   │   ├── dnc_sort_vector.dot
    │   │   ├── dnc_temporal_link_matrix.dot
    │   │   ├── dnc_usage_vector.dot
    │   │   ├── dnc_vector_content_based_addressing.dot
    │   │   ├── dnc_write_content_weighting.dot
    │   │   └── dnc_write_weighting.dot
    │   ├── top
    │   │   ├── dnc_interface_matrix.dot
    │   │   ├── dnc_interface_top.dot
    │   │   ├── dnc_interface_vector.dot
    │   │   ├── dnc_output_vector.dot
    │   │   └── dnc_top.dot
    │   └── trained
    │       └── dnc_trained_top.dot
    ├── ntm
    │   ├── memory
    │   │   ├── ntm_addressing.dot
    │   │   ├── ntm_matrix_content_based_addressing.dot
    │   │   └── ntm_vector_content_based_addressing.dot
    │   ├── read_heads
    │   │   └── ntm_reading.dot
    │   ├── top
    │   │   ├── ntm_interface_matrix.dot
    │   │   ├── ntm_interface_top.dot
    │   │   ├── ntm_interface_vector.dot
    │   │   ├── ntm_output_vector.dot
    │   │   └── ntm_top.dot
    │   ├── trained
    │   │   └── ntm_trained_top.dot
    │   └── write_heads
    │       ├── ntm_erasing.dot
    │       └── ntm_writing.dot
    ├── state
    │   ├── feedback
    │   │   ├── ntm_state_matrix_feedforward.dot
    │   │   ├── ntm_state_matrix_input.dot
    │   │   ├── ntm_state_matrix_output.dot
    │   │   └── ntm_state_matrix_state.dot
    │   ├── outputs
    │   │   ├── ntm_state_vector_output.dot
    │   │   └── ntm_state_vector_state.dot
    │   └── top
    │       └── ntm_state_top.dot
    └── trainer
        ├── differentiation
        │   ├── ntm_matrix_controller_differentiation.dot
        │   └── ntm_vector_controller_differentiation.dot
        ├── FNN
        │   ├── ntm_fnn_b_trainer.dot
        │   ├── ntm_fnn_d_trainer.dot
        │   ├── ntm_fnn_k_trainer.dot
        │   ├── ntm_fnn_trainer.dot
        │   ├── ntm_fnn_u_trainer.dot
        │   ├── ntm_fnn_v_trainer.dot
        │   └── ntm_fnn_w_trainer.dot
        └── LSTM
            ├── activation
            │   ├── ntm_lstm_activation_b_trainer.dot
            │   ├── ntm_lstm_activation_d_trainer.dot
            │   ├── ntm_lstm_activation_k_trainer.dot
            │   ├── ntm_lstm_activation_trainer.dot
            │   ├── ntm_lstm_activation_u_trainer.dot
            │   ├── ntm_lstm_activation_v_trainer.dot
            │   └── ntm_lstm_activation_w_trainer.dot
            ├── forget
            │   ├── ntm_lstm_forget_b_trainer.dot
            │   ├── ntm_lstm_forget_d_trainer.dot
            │   ├── ntm_lstm_forget_k_trainer.dot
            │   ├── ntm_lstm_forget_trainer.dot
            │   ├── ntm_lstm_forget_u_trainer.dot
            │   ├── ntm_lstm_forget_v_trainer.dot
            │   └── ntm_lstm_forget_w_trainer.dot
            ├── input
            │   ├── ntm_lstm_input_b_trainer.dot
            │   ├── ntm_lstm_input_d_trainer.dot
            │   ├── ntm_lstm_input_k_trainer.dot
            │   ├── ntm_lstm_input_trainer.dot
            │   ├── ntm_lstm_input_u_trainer.dot
            │   ├── ntm_lstm_input_v_trainer.dot
            │   └── ntm_lstm_input_w_trainer.dot
            └── output
                ├── ntm_lstm_output_b_trainer.dot
                ├── ntm_lstm_output_d_trainer.dot
                ├── ntm_lstm_output_k_trainer.dot
                ├── ntm_lstm_output_trainer.dot
                ├── ntm_lstm_output_u_trainer.dot
                ├── ntm_lstm_output_v_trainer.dot
                └── ntm_lstm_output_w_trainer.dot

259 directories, 812 files
